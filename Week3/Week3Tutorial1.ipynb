{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week3Tutorial1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPjeM/vIR3/1BqH3xpUCDy6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ebatty/MathToolsforNeuroscience/blob/master/Week3/Week3Tutorial1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9l0lyqLvkW7"
      },
      "source": [
        "# Week 3: Linear Algebra III\n",
        "\n",
        "# Tutorial 1\n",
        "\n",
        "# [insert your name]\n",
        "\n",
        "**Important reminders**: Before starting, click \"File -> Save a copy in Drive\". Produce a pdf for submission by \"File -> Print\" and then choose \"Save to PDF\".\n",
        "\n",
        "To complete this tutorial, you should have watched Videos 3.1 and 3.2.\n",
        "\n",
        "You can change the theme of a jupyter notebook between dark and light (black vs white background): Go to Tools -> Settings -> theme. Specify which theme you are using below so the plots change accordingly. I think dark mode is prettier/nicer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3dNes5ing9w"
      },
      "source": [
        "your_theme = 'dark' # change this to light for plots that work well with white background"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cv9HSBNPyLV9",
        "cellView": "form"
      },
      "source": [
        "# @title \n",
        "# @markdown Imports\n",
        "\n",
        "# Imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import scipy.linalg\n",
        "from matplotlib.animation import FuncAnimation\n",
        "\n",
        "# Plotting parameters\n",
        "from IPython.display import HTML\n",
        "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
        "matplotlib.rcParams.update({'font.size': 22})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIdPVYl9TzmK",
        "cellView": "form"
      },
      "source": [
        "# @title \n",
        "# @markdown Plotting functions\n",
        "if your_theme == 'dark':  \n",
        "  plt.style.use(['dark_background'])\n",
        "  classic = 'w'\n",
        "else:\n",
        "  classic = 'k'\n",
        "\n",
        "def plot_eig_vec_transform(W):\n",
        "  vec_names = ['a', 'b','c','d','e','f','g', 'h']\n",
        "\n",
        "  _, vecs = np.linalg.eig(W)\n",
        "  vecs = vecs.T\n",
        "\n",
        "  fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "  colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
        "\n",
        "  for i in range(2):\n",
        "    axes[i].set(xlim=[-3.5, 3.5], ylim=[-3.5,3.5])\n",
        "    axes[i].axis('Off')\n",
        "    axes[i].plot([0, 0], [-3.5, 3.5], classic, alpha=.4)\n",
        "    axes[i].plot([-3.5, 3.5], [0, 0], classic, alpha=.4)\n",
        "\n",
        "  for i_vec, vec in enumerate(vecs):    \n",
        "    axes[0].arrow(0, 0, vec[0], vec[1], head_width=.2, facecolor=colors[i_vec], edgecolor=colors[i_vec], length_includes_head=True)\n",
        "    axes[0].annotate(vec_names[i_vec], xy=(vec[0]+np.sign(vec[0])*.15, vec[1]+np.sign(vec[1])*.15), color=colors[i_vec])\n",
        "\n",
        "    transformed_vec = np.matmul(W, vec)\n",
        "    axes[1].arrow(0, 0, transformed_vec[0], transformed_vec[1], head_width=.2, facecolor=colors[i_vec], edgecolor=colors[i_vec], length_includes_head=True)\n",
        "    axes[1].annotate(vec_names[i_vec], xy=(transformed_vec[0]+np.sign(transformed_vec[0])*.15, transformed_vec[1]+np.sign(transformed_vec[1])*.15), color=colors[i_vec])\n",
        "\n",
        "  axes[0].set_title('Before')\n",
        "  axes[1].set_title('After')\n",
        "\n",
        "def animate_circuit_responses(u, W, xlim='default', ylim='default'):\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(10,10))\n",
        "\n",
        "    # Set up axis limits\n",
        "    if xlim =='default':\n",
        "      xlim = [np.minimum(np.min(u), 0), np.maximum(np.max(u)+5, 0)]\n",
        "    if ylim == 'default':\n",
        "      ylim = [np.minimum(np.min(u), 0), np.maximum(np.max(u)+5, 0)]\n",
        "\n",
        "    # Set up look\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    cs = plt.rcParams['axes.prop_cycle'].by_key()['color']*10\n",
        "    ax.set_xlim(xlim)\n",
        "    ax.set_ylim(ylim)\n",
        "\n",
        "    # Set up tracking textz\n",
        "    tracker_text = ax.text(.5, .9, \"\", color='w', fontsize=20, verticalalignment='top', horizontalalignment='left', transform=ax.transAxes)\n",
        "\n",
        "    # Plot eigenvectors\n",
        "    eigvals, eigvecs = np.linalg.eig(W)\n",
        "\n",
        "\n",
        "    if np.abs(eigvals[0]) < np.abs(eigvals[1]):\n",
        "      lc1 = 'c'\n",
        "      lc2 = 'g'\n",
        "    else:\n",
        "      lc1 = 'g'\n",
        "      lc2 = 'c'\n",
        "\n",
        "    ax.plot(np.arange(-10000, 10000)*eigvecs[0, 0], np.arange(-10000, 10000)*eigvecs[1, 0],lc1, alpha=.5)\n",
        "    ax.plot(np.arange(-10000, 10000)*eigvecs[0, 1], np.arange(-10000, 10000)*eigvecs[1, 1], lc2, alpha=.5)\n",
        "\n",
        "\n",
        "    # Set up scatter \n",
        "    scatter = ax.scatter([], [], alpha=1, c=cs[0]) \n",
        "\n",
        "    # Update function during animation\n",
        "    def update(num):\n",
        "        scatter.set_offsets(u[:, :(num+1)].T)\n",
        "        scatter.set_facecolors(cs[:(num)])\n",
        "\n",
        "        track_string = '   t = '+str(num)+'\\n$N_1$ = '+str(round(u[0,num], 2))+' \\n$N_2$ = '+str(round(u[1,num], 2))+''\n",
        "        tracker_text.set_text(track_string)\n",
        "\n",
        "    \n",
        "    # Make/display animation\n",
        "    ani = FuncAnimation(fig, update, T, interval=10000/T, blit=False)\n",
        "    plt.close(fig)\n",
        "    return ani, eigvals, eigvecs\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtUJK2gYommf"
      },
      "source": [
        "# Key concept review & coding tips\n",
        "\n",
        "## Eigenvectors & eigenvalues\n",
        "\n",
        "\n",
        "*   An eigenvector is a vector that doesn't change direction in a transformation ($\\bar{v}$ below).\n",
        "*   The associated eigenvalue is the factor by which the eigenvector is scaled ($\\lambda$ below). \\\\\n",
        "$$A\\bar{v} = \\lambda\\bar{v} $$\n",
        "\n",
        "*   `np.linalg.eig` gives you the eigenvalues and eigenvectors of a matrix.\n",
        "*  Eigenvalues are more specifically defined than eigenvectors: for an eigenvector $\\bar{v}$, $-2\\bar{v}$ and $6\\bar{v}$ are also eigenvectors. In other words, there are an infinite number of eigenvectors for a given eigenvalue that lie along the same line. For this reason, we often use unit eigenvectors (although this does not account for flipping between negative/positive). \n",
        "*  Additionally, sometimes all of the vectors in a plane (or more in higher D space) can be eigenvectors for a given eigenvalue. This will not always be obvious from the outputs of `np.linalg.eig`.\n",
        "*  You will not necessarily be able to form a basis for a space from the eigenvectors.\n",
        "*  We solve for the eigenvalues of matrix $B$ by solving det($B$ - $\\lambda I$) = 0.\n",
        "* Complex eigenvalues exist and have associated complex eigenvectors - a matrix with complex eigenstuff performs some kind of rotation.\n",
        "*  Nonsquare matrices do not have eigenvalues.\n",
        "* An n x n matrix has n eigenvalues but they could be real or complex and they are not necessarily distinct (meaning a matrix could have two eigenvalues of 2, with different associated eigenvectors).\n",
        "\n",
        "## Eigenstuff in neural circuits\n",
        "\n",
        "*  We can model a neural circuit as a discrete dynamical system. If $\\bar{u}_t$ is the vector of neural activity at time $t$ and $W$ is the synaptic weight matrix, then:\n",
        "$$\\bar{u}_{t+1} = W\\bar{u}_t $$ \n",
        "*  The eigenvalues/eigenvectors of W can help us understand the system and what will happen given initial responses $\\bar{u}_0$. \n",
        "\n",
        "Assuming $W$ is diagonalizable (aka we can form an eigenbasis, aka we have N linearly independent eigenvectors):\n",
        "* If the absolute values  of all the eigenvalues of W are greater than 1, the system will diverge to infinity.\n",
        "* If the absolute values  of all the eigenvalues of W are less than 1, the system will converge to the origin.\n",
        "* If the eigenvalues are all equal to 1, the system will stay at the initial state.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31yvHJrIX97I"
      },
      "source": [
        "# Exercise 1: Eigenvectors & transformations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYNHs839bEyC"
      },
      "source": [
        "## A) Identifying eigenvectors\n",
        "\n",
        "Below we plot some vectors before a linear transformation by a matrix and after. Which of the vectors are eigenvectors?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d57H5HRvbQGj",
        "cellView": "form"
      },
      "source": [
        "# @title\n",
        "# @markdown Execute this cell to visualize vectors\n",
        "\n",
        "vec_names = ['a', 'b','c','d','e','f','g', 'h']\n",
        "vecs = np.array([[0, 1], \n",
        "                 [1/np.sqrt(2), 1/np.sqrt(2)],\n",
        "                 [1, 0],\n",
        "                 [1/np.sqrt(2), -1/np.sqrt(2)],\n",
        "                 [0, -1], \n",
        "                 [-2/np.sqrt(5), -1/np.sqrt(5)],\n",
        "                 [-1, 0], \n",
        "                 [-2/np.sqrt(5), 1/np.sqrt(5)], \n",
        "                 ])\n",
        "W = np.array([[1.4, 1.2], [0, 1]])\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
        "\n",
        "for i in range(2):\n",
        "  axes[i].set(xlim=[-2, 2], ylim=[-2,2])\n",
        "  axes[i].axis('Off')\n",
        "\n",
        "for i_vec, vec in enumerate(vecs):    \n",
        "  axes[0].arrow(0, 0, vec[0], vec[1], head_width=.2, facecolor=colors[i_vec], edgecolor=colors[i_vec], length_includes_head=True)\n",
        "  axes[0].annotate(vec_names[i_vec], xy=(vec[0]+np.sign(vec[0])*.15, vec[1]+np.sign(vec[1])*.15), color=colors[i_vec])\n",
        "\n",
        "  transformed_vec = np.matmul(W, vec)\n",
        "  axes[1].arrow(0, 0, transformed_vec[0], transformed_vec[1], head_width=.2, facecolor=colors[i_vec], edgecolor=colors[i_vec], length_includes_head=True)\n",
        "  axes[1].annotate(vec_names[i_vec], xy=(transformed_vec[0]+np.sign(transformed_vec[0])*.15, transformed_vec[1]+np.sign(transformed_vec[1])*.15), color=colors[i_vec])\n",
        "\n",
        "axes[0].set_title('Before')\n",
        "axes[1].set_title('After');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWIDB6bWbOPg"
      },
      "source": [
        "**Your text answer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZsNRW18bQ5o"
      },
      "source": [
        "## B) Describing transformations with eigenvectors\n",
        "\n",
        "Last week, we learned how to think about linear transformations in terms of where the unit vectors end up. We can also think about them in terms of eigenvectors. Just by looking at eigenvectors before and after a transformation, can you describe what the transformation is in words? \n",
        "\n",
        "Note that I show an eigenvector for every eigenvalue. The x/y limits do not change in before vs after (so eigenvectors are showed scaled by the eigenvalues).\n",
        "\n",
        "\n",
        "Here are some transformation words to jog your memory: contraction, expansion, horizontal vs vertical, shear, projection onto an axis, reflection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uObSMAJgjqOE",
        "cellView": "form"
      },
      "source": [
        "# @title\n",
        "# @markdown Execute this cell to visualize vectors\n",
        "\n",
        "W = np.array([[3, 0], [0, 1]])\n",
        "plot_eig_vec_transform(W)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gioIqdJjnKv"
      },
      "source": [
        "**Your text answer for plot above**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_kNJGz1lXkl",
        "cellView": "form"
      },
      "source": [
        "# @title\n",
        "# @markdown Execute this cell to visualize vectors\n",
        "\n",
        "W = np.array([[0, 1], [1, 0]])\n",
        "plot_eig_vec_transform(W)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7QrbncTlfcg"
      },
      "source": [
        "**Your text answer for plot above**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHwhFedI86GO"
      },
      "source": [
        "# Exercise 2: Eigenstuff of a matrix squared\n",
        "\n",
        "This is a guided proof. Consider the matrix $A$ with eigenvalues $\\lambda$. We want to answer the following question: what are the eigenvectors and eigenvalues of $A^2$?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS91ESGy9Xwk"
      },
      "source": [
        "i) Write down the relationship between $A$ and its eigenvalues $\\lambda$ and eigenvectors $\\bar{v}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S72KKiFg9j-M"
      },
      "source": [
        "**Your math answer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSLpCUbp9ncX"
      },
      "source": [
        "ii) Multiply both sides of the equation by $A$. Is there anything on the right-hand side that you can replace $A\\bar{v}$ with?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38rd20K99zNF"
      },
      "source": [
        "**Your math answer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjC7Zbmp9_yh"
      },
      "source": [
        "iii) What are the eigenvalues and eigenvectors of $A^2$?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOMntjTw94S2"
      },
      "source": [
        "**Your math/text answer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZL_-e6cW-HG2"
      },
      "source": [
        "# Exercise 3: Complex computations\n",
        "\n",
        "We saw in Video 3.2 that eigenvalues can be complex - let's convince ourselves of this. Consider the following rotation matrix:\n",
        "\n",
        "$$B = \n",
        "\\begin{bmatrix}\n",
        "0 & -1 \\\\\n",
        "1 & 0 \\\\\n",
        "\\end{bmatrix} $$\n",
        "\n",
        "Calculate the eigenvalues of this matrix using the method we learned in class (use det($B$ - $\\lambda I$) = 0 to solve for $\\lambda$).\n",
        "\n",
        "Discuss (no need to explicitly answer): why does it make sense that a rotation has no real eigenvalues?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksX-8GUo_LQv"
      },
      "source": [
        "**Your math answer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZoiPTTV_PmJ"
      },
      "source": [
        "# Exercise 4: Neural circuit dynamics\n",
        "\n",
        "Consider a two neuron circuit with the following synaptic connectivity matrix:\n",
        "\n",
        "$$W = \\begin{bmatrix}\n",
        "1 & 3 \\\\\n",
        "4 & 2 \\\\\n",
        "\\end{bmatrix} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYLByKEzA7S-"
      },
      "source": [
        "## A) Drawing the circuit\n",
        "\n",
        "Draw this two neuron circuit with the labeled synaptic weights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lw6md0MzA-Pp"
      },
      "source": [
        "**Your drawn diagram here**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRfINPF4BB2x"
      },
      "source": [
        "## B) Computing eigenstuff with code\n",
        "Calculate the eigenvalues and the eigenvectors of W using `np.linalg.eig` and print them. Make sure you understand what the outputs are! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwi-oHq48-gM"
      },
      "source": [
        "eigvals, eigvecs = ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1VhyfkfBzj0"
      },
      "source": [
        "Prove to yourself that the computer is right. Multiply W with one of your computed eigenvectors and make sure it equals the associated eigenvalue times that eigenvector. Print True if these resulting vectors are equal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "411Awqo4BuC1"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeWRWX1X-kmi"
      },
      "source": [
        "Do you expect the system to converge to the origin or diverge to infinity? Why?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeXcfyEx-oRA"
      },
      "source": [
        "**Your text answer here**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxuBrUGYBk10"
      },
      "source": [
        "## C) Modeling the circuit\n",
        "\n",
        "Complete the function below for computing $\\bar{u}$ over time.  \n",
        "\n",
        "You will then see an animation of $\\bar{u}$ over time using a provided function `animate_circuit_responses`. The blue/green lines in this animation show the span of the eigenvectors: green represents the eigenvectors with the largest magnitude eigenvalue. Feel free to change the axis limits to see interesting parts of space (xlim/ylim arguments).\n",
        "\n",
        "\n",
        "Assume an input vector (initial condition) $\\bar{u}_0 = \\begin{bmatrix}\n",
        "1 \\\\\n",
        "1  \\\\\n",
        "\\end{bmatrix}$. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvJN4EXUBVt2"
      },
      "source": [
        "def circuit_implementation(W, u0, T):\n",
        "  \"\"\" Simulate the responses of N neurons over time given their connections\n",
        "\n",
        "  Args:\n",
        "    W (ndarray): weight matrix of synaptic connections, should be N x N\n",
        "    u0 (ndarray): initial condition or input vector, should be N,\n",
        "    T (scalar): number of time steps to run simulation for\n",
        "\n",
        "  Returns:\n",
        "    u (ndarray): the neural responses over time, should be N x T\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Compute the number of neurons\n",
        "  N = W.shape[0] \n",
        "\n",
        "  # Initialize empty response array and initial condition\n",
        "  u = np.zeros((N, T))\n",
        "  u[:, 0]  = u0\n",
        "\n",
        "  ## Your code here! \n",
        "  # You should loop over time steps and compute u(t+1) based on u(t), and store in \n",
        "  # appropriate column of u (each column is a time step)\n",
        "\n",
        "  # Comment out below when you have finished\n",
        "  raise NotImplementedError('Student code here')\n",
        "\n",
        "  return u\n",
        "\n",
        "\n",
        "W = np.array([[1, 3], [4, 2]])\n",
        "u0 = np.array([1, 1])\n",
        "T = 6\n",
        "\n",
        "u = circuit_implementation(W, u0, T)\n",
        "\n",
        "ani, eigvals, eigvecs = animate_circuit_responses(u, W, xlim=[-720, 720], ylim=[-720, 720]) \n",
        "ani"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62sOQhw2UrLr"
      },
      "source": [
        "What are the activities of $N_1$ and $N_2$ after 5 timesteps? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yWSGH_-Ux8m"
      },
      "source": [
        "**Your math/text answer here**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SpxRe2FDGhu"
      },
      "source": [
        "What are the activities of $N_1$ and $N_2$ after 5 timesteps if you start with initial condition $\\bar{u}_0 = \\begin{bmatrix}\n",
        "-3 \\\\\n",
        "-1  \\\\\n",
        "\\end{bmatrix}$. Note that we are allowing our neural activities to be negative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBoMGq9zDQDB"
      },
      "source": [
        "**Your math/text answer here**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZkPu_imU1NT"
      },
      "source": [
        "## D) Mixed eigenvalues\n",
        "\n",
        "In Video 3.2, **I** mostly discussed matrices that had either all eigenvalues with absolute value greater than 1 or all eigenvalues with absolute value less than 1. Let's explore a new weight matrix that has one eigenvalue above 1 and one below:\n",
        "\n",
        "$$W = \\begin{bmatrix}\n",
        "1 & .2 \\\\\n",
        ".1 & 1 \\\\\n",
        "\\end{bmatrix} $$\n",
        "\n",
        "Use the animation below to answer i-iii by changing the initial condition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mv569xOOUoYI"
      },
      "source": [
        "u0 = ...\n",
        "\n",
        "W = np.array([[1, .2], [.1, 1]])\n",
        "T = 25\n",
        "\n",
        "u = circuit_implementation(W, u0, T)\n",
        "ani, eigvals, eigvecs = animate_circuit_responses(u, W, xlim=[-15, 15], ylim=[-15, 15]) \n",
        "ani"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiSOz_xq_ZH5"
      },
      "source": [
        "i) Look at what happens when the initial inputs $\\bar{u}_0 = \\begin{bmatrix}\n",
        "1 \\\\\n",
        "2  \\\\\n",
        "\\end{bmatrix}$. What do you notice about the activities of $N_1$ and $N_2$ and how they relate to the eigenvectors?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIRfnBi1ACOs"
      },
      "source": [
        "**Your text answer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2jSX9GL_38H"
      },
      "source": [
        "ii) Now look at the initial condition $\\bar{u}_0 = \\begin{bmatrix}\n",
        "-1 \\\\\n",
        "1  \\\\\n",
        "\\end{bmatrix}$. What happens? Describe in words the evolution of $N_1$ and $N_2$ and how it relates to the eigenvectors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jsjg5mWhAPmI"
      },
      "source": [
        "**Your text answer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiTbOrCMAWzN"
      },
      "source": [
        "iii) Can you design an initial condition so that the system converges to the origin (the response of both neurons goes to 0)? Give such a condition if it exists."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DEEWMILAgN3"
      },
      "source": [
        "**Your math/text answer**"
      ]
    }
  ]
}